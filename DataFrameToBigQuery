from google.cloud import bigquery
import pandas as pd
import logging

logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')

class DataFrameToBigQuery:
    """
    A utility class for appending data from a pandas DataFrame to a Google BigQuery table.

    Attributes:
        project_id (str): Google Cloud project ID.
        dataset_id (str): BigQuery dataset ID.
        table_id (str): BigQuery table ID.
        client (bigquery.Client): BigQuery client for interacting with the API.
        table_ref (bigquery.TableReference): Reference to the BigQuery table.
        table (bigquery.Table): BigQuery table object.

    Methods:
        adjust_dataframe_columns(dataframe): Adjusts the columns of the provided DataFrame to match the schema of the BigQuery table.
        append_to_table(dataframe): Appends the data from the provided DataFrame to the BigQuery table.
    """
    def __init__(self, project_id, dataset_id, table_id):
        """
        Initializes the DataFrameToBigQuery class with the specified project, dataset, and table IDs.

        Args:
            project_id (str): Google Cloud project ID.
            dataset_id (str): BigQuery dataset ID.
            table_id (str): BigQuery table ID.
        """
        self.project_id = project_id
        self.dataset_id = dataset_id
        self.table_id = table_id
        self.client = bigquery.Client(project=self.project_id)
        self.table_ref = self.client.dataset(self.dataset_id).table(self.table_id)
        self.table = self.client.get_table(self.table_ref)


    def adjust_dataframe_columns(self, dataframe):
        """
        Adjusts the columns of the provided DataFrame to match the schema of the BigQuery table.
        It truncates extra columns and renames the DataFrame's columns to match the BigQuery table's schema.

        Args:
            dataframe (pd.DataFrame): The pandas DataFrame to adjust.

        Returns:
            pd.DataFrame: The adjusted DataFrame.
        """
        bq_fields_count = len(self.table.schema)
        df_num_col = len(dataframe.columns)
        if df_num_col > bq_fields_count:
            dataframe = dataframe.iloc[:, :bq_fields_count]
            logging.warning(f"El DataFrame se ha ajustado de {df_num_col} a {bq_fields_count} columnas para coincidir con la tabla de destino en BigQuery.")
        schema = self.table.schema
        column_mapping = {dataframe.columns[i]: field.name for i, field in enumerate(schema) if
                          i < len(dataframe.columns)}
        dataframe = dataframe.rename(columns=column_mapping)
        return dataframe


    def append_to_table(self, dataframe):
        """
        Appends the data from the provided DataFrame to the BigQuery table.
        It first adjusts the DataFrame columns to match the BigQuery table schema and then performs the append operation.

        Args:
            dataframe (pd.DataFrame): The pandas DataFrame to append.
        """
        dataframe = self.adjust_dataframe_columns(dataframe)
        job = self.client.load_table_from_dataframe(dataframe, self.table_ref, job_config=bigquery.LoadJobConfig(write_disposition="WRITE_APPEND"))
        job.result()  # Espera a que la carga se complete
        logging.info(f"Se han cargado {job.output_rows} filas a {self.dataset_id}.{self.table_id}.")
